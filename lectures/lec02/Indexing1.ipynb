{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<br>\n",
    "## CS 429: Information Retrieval\n",
    "## Lecture 2: Indexing\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dr. Aron Culotta\n",
    "### Illinois Institute of Technology \n",
    "\n",
    "<br><br><br>\n",
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Indexing Pipeline\n",
    "\n",
    "1. Collect documents\n",
    "2. Tokenize\n",
    "3. Normalize\n",
    "4. Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Indexing Pipeline\n",
    "\n",
    "document $\\xrightarrow{tokenize}$ (tokens, types) $\\xrightarrow{normalize}$ terms $\\xrightarrow{index}$ inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Collect documents.\n",
    "document = \"he didn't know where he worked.\"\n",
    "\n",
    "# 2. Tokenize\n",
    "tokens = [\"he\", \"didn't\", \"know\", \"where\", \"he\", \"worked\"] # split; remove punctuation\n",
    "types = [\"he\", \"didn't\", \"know\", \"where\", \"worked\"] # unique tokens.\n",
    "\n",
    "# 3. Normalize\n",
    "# remove common words like 'where'; collapse word forms like worked -> work\n",
    "terms = [\"he\", \"didnt\", \"know\", \"work\"]\n",
    "\n",
    "# 4. Index\n",
    "index = {'he': [0],\n",
    "         'didnt': [0],\n",
    "         'know' : [0],\n",
    "         'work' : [0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**e·quiv·a·lence class** (/i'kwivələns klas/) *n.*\n",
    "\n",
    "1. A subset whose elements are equivalent according to some relation $\\sim$ .\n",
    "\n",
    "    $S' \\subseteq S \\hspace{.2cm}$ s.t. $\\hspace{.2cm}x_i \\sim x_j \\hspace{.1cm} \\forall x_i, x_j \\in S'$\n",
    "    \n",
    "    E.g., consider the set \\{dog, cat, spider\\} and the relation \"has same number of legs\". Then there are two equivalence classes: \\{dog, cat\\} and \\{spider\\}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**to·ken** (/tōkən/) *n*.\n",
    "\n",
    "1. A sequence of characters in a document that form a meaningful unit.\n",
    "2. The output of a *tokenizer*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**type** (/tīp/) *n.*\n",
    "\n",
    "1. An equivalence class of *tokens* under the string equality relation.\n",
    "2. By analogy to OO-programming, class:object :: type:token\n",
    "\n",
    "    *e.g., \"to be or not to be\"* $\\xrightarrow{tokenize}$ *tokens={to, be, or, not, to, be}* $\\hspace{.2cm}$  *types={to, be, or, not}*\n",
    "    \n",
    "    The type 'to' is an equivalence class containing the first and fifth tokens of the document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**term** (/tərm/) *n.*\n",
    "\n",
    "1. An equivalence class of *types* under the relation \"have the same normalized form.\"\n",
    "2. The keys in the inverted index.\n",
    "\n",
    "    e.g., types={John, john, aren't, arent} $\\xrightarrow{normalize}$ terms={john, arent}.\n",
    "\n",
    "    The term \"john\" is an equivalence class containing types {John, john}.\n",
    "    \n",
    "    The term \"arent\" is an equivalence class containing types {arent, aren't}.\n",
    "    \n",
    "    \n",
    "<br><br><br>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenization\n",
    "\n",
    "**to·ken·i·za·tion** (/ˈtōkən izā-shən/) *n.*\n",
    "\n",
    "1. The process of splitting a document into tokens.\n",
    "\n",
    "    *Simplest approach*: split on whitespace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "document.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'what     about multiple     spaces?'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenization: Compound Nouns\n",
    "\n",
    "- *San Francisco*;  *New York University* vs *York University*\n",
    "- Solved somewhat by *phrase indexing* (next class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenization: Segmentation\n",
    "\n",
    "- *Lebensversicherungsgesellschaftsangestellter*\n",
    "  - \"life insurance company employee\"\n",
    "- 我不能说中国话\n",
    "- *\\#androidgames*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Statistical classification algorithms can be used to split (Part III of course). \n",
    "- Simpler: index character subsequences (*n-grams*).\n",
    "  - E.g., *\\#androidgames* $\\rightarrow$ {*#andr, andro, ndroi, droid, roidg, ..., games*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenization: Punctuation\n",
    "\n",
    "- Remove all punctuation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - \"didn't\", \"www.google.com\"\n",
    "  - [CAR](https://www.google.com/search?q=CAR) vs [C.A.R](https://www.google.com/search?q=C.A.R.).\n",
    "  - [O'Neill vs ONeill vs O Neill](https://www.google.com/#q=oneill+-o'neill&safe=active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenization: Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "symbol | meaning\n",
    "------ | -------\n",
    "\\b\t| Word boundary (zero width)\n",
    "\\d\t| Any decimal digit (equivalent to [0-9])\n",
    "\\D\t| Any non-digit character (equivalent to [^0-9])\n",
    "\\s\t| Any whitespace character (equivalent to [ \\t\\n\\r\\f\\v]\n",
    "\\S\t| Any non-whitespace character (equivalent to [^ \\t\\n\\r\\f\\v])\n",
    "\\w\t| Any alphanumeric character (equivalent to [a-zA-Z0-9_])\n",
    "\\W\t| Any non-alphanumeric character (equivalent to [^a-zA-Z0-9_])\n",
    "\\t\t| The tab character\n",
    "\\n\t| The newline character\n",
    "\n",
    "(source: <http://nltk.org/book/ch03.html>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import re  # Regular expression module\n",
    "re.split('x', 'axbxc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(re.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.split('x+', 'axxxxbxxxxc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.split('x', 'axxxxbxxxxc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "re.split('\\+\\+', 'hi+++there')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "re.split('([\\W\\s]|t)', \"what's up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = \"A first-class ticket to the U.S.A. isn't expensive?\"\n",
    "re.split(' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How to remove punctuation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "re.split('\\W+', text)           # \\W=not a word character; +=1 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "re.findall('\\w+', text)         # \\w=a word character [a-zA-Z0-9_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# group punctuation with following letters\n",
    "re.findall('\\w+|\\S\\w*', text)  # \\S=not a space; |=OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How to keep hyphenated words and contractions together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "re.findall(\"\\w+(?:[-']\\w+)*|[-.(]+|\\S\\w*\", text)\n",
    "# (?: specifies what to match, not what to capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "re.findall(\"(?:[A-Z]\\.)+|\\w+(?:[-']\\w+)*|[-.(]+|\\S\\w*\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Normalization\n",
    "\n",
    "**nor·mal·iz·a·tion** (/ˈnôrməˌlizā-shən/) *n.*\n",
    "\n",
    "1. The process of clustering *types* into *terms*.\n",
    "\n",
    "    Issues include: removing common words, special characters, casing, morphology\n",
    "    \n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Normalization: Stop words\n",
    "\n",
    "- Exclude common words\n",
    "  - *the*, *a*, *be*\n",
    "- Why?\n",
    "\n",
    "<br><br><br>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - save space (length of postings list is huge!)\n",
    "  - no semantic content (?!)\n",
    "  \n",
    "  <br><br><br>\n",
    "  <br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*\"[to be or not to be](https://www.google.com/search?q=to+be+or+not+to+be&oq=to+be+or+not+to+be)\"* is all stop words!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accents/Diacritics\n",
    "\n",
    "- naive vs. naïve\n",
    "- pena (sorrow) vs peña (cliff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What will users enter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Case\n",
    "\n",
    "- Typically, just convert everything to lowercase.\n",
    "- E.g., search Google for [CAT -cat](https://www.google.com/search?q=CAT+-cat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stemming / Lemmatizing\n",
    "\n",
    "**mor·phol·o·gy** (/môrˈfäləjē/) *n.*\n",
    "\n",
    "1. (*Linguistics*) The study of the rules governing how words may take different forms in a language.\n",
    "\n",
    "*E.g.* \n",
    "\n",
    "- Pluralization: *dog* $\\xrightarrow{pluralize}$ *dogs* ; *goose* $\\xrightarrow{pluralize}$ *geese*\n",
    "\n",
    "\n",
    "- Tense: *play* $\\xrightarrow{past.tense}$ *played* ; *go* $\\xrightarrow{past.tense}$ *went*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**stem** (/stem/) *v.*\n",
    "\n",
    "1. To normalize based on crude morphology heuristics.\n",
    "\n",
    "    *E.g. remove all \"-s\" and \"-ed\" suffixes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**lem·ma·tize** (ˈleməˌtīz/) *v.*\n",
    "\n",
    "1. To create equivalence classes of word types using the morphological rules of a language.\n",
    "\n",
    "    *Often relies on **part-of-speech** tagging to select rules*.\n",
    "\n",
    "    *E.g. if * bed * is a noun, then do not remove * -ed *suffix.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple stemmer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = 'hello'\n",
    "s[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    for suffix in ['ies', 's', 'ed', 'ing']: # order matters!\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**What can go wrong?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stemming Errors\n",
    "\n",
    "- **over-stemming**: merge types that should not be merged.\n",
    "- **under-stemming**: fail to merge types that should be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "types = ['tied', 'ties', 'tis', 'bed', 'cities']\n",
    "[stem(w) for w in types]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**How does this affect search?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Porter Stemmer\n",
    "\n",
    "- Very commonly used stemmer with a complex set of heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer # See nltk.org (`pip install nltk`)\n",
    "# http://tartarus.org/~martin/PorterStemmer/\n",
    "# Original paper: http://web.simmons.edu/~benoit/lis466/PorterStemmingAlgorithm.pdf\n",
    "porter = PorterStemmer()\n",
    "print(types)\n",
    "[porter.stem(x) for x in types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "porter.stem('city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "types = ['bed', 'kiss',\n",
    "         'tied', 'tis',\n",
    "         'universal', 'university',\n",
    "         'experiment', 'experience',\n",
    "         'past', 'paste',\n",
    "         'alumnus', 'alumni',\n",
    "         'adhere', 'adhesion',\n",
    "         'create', 'creation']\n",
    "porter_results = [porter.stem(x) for x in types]\n",
    "porter_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# See description: https://wordnet.princeton.edu/wordnet/man/morphy.7WN.html\n",
    "lemm = WordNetLemmatizer()\n",
    "lemm_results = [lemm.lemmatize(x) for x in types]\n",
    "print('%15s\\t%15s\\t%15s' % ('type', 'porter', 'lemmatizer'))\n",
    "print('\\n')\n",
    "print('\\n'.join(['%15s\\t%15s\\t%15s' % (t[0], t[1], t[2])\n",
    "                 for t in zip(types, porter_results, lemm_results)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(lemm.lemmatize('are'))\n",
    "print(lemm.lemmatize('is'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(lemm.lemmatize('are', 'v'))\n",
    "print(lemm.lemmatize('is', 'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A principled approach?\n",
    "\n",
    "Given the many number of ways to preprocess text, how do we know which one is best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Approaches:\n",
    "\n",
    "- Assume types that appear in similar contexts can be merged.\n",
    "  - e.g., *universally* and *universal* appear in similar documents, but not *university*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Learn from user behavior\n",
    "  - e.g., users click on very different search results if they search for *universal* vs *university*.\n",
    "  \n",
    "We'll explore both later in the course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
