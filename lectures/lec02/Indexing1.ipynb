{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# CS 429: Information Retrieval\n",
      "\n",
      "<br>\n",
      "## Lecture 2: Indexing\n",
      "\n",
      "<br>\n",
      "\n",
      "### Dr. Aron Culotta\n",
      "### Illinois Institute of Technology \n",
      "### Spring 2014\n",
      "\n",
      "---\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Indexing Pipeline\n",
      "\n",
      "1. Collect documents\n",
      "2. Tokenize\n",
      "3. Normalize\n",
      "4. Index"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Indexing Pipeline\n",
      "\n",
      "document $\\xrightarrow{tokenize}$ (tokens, types) $\\xrightarrow{normalize}$ terms $\\xrightarrow{index}$ inverted index"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 1. Collect documents.\n",
      "document = \"he didn't know where he worked.\"\n",
      "\n",
      "# 2. Tokenize\n",
      "tokens = [\"he\", \"didn't\", \"know\", \"where\", \"he\", \"worked\"] # split; remove punctuation\n",
      "types = [\"he\", \"didn't\", \"know\", \"where\", \"worked\"] # unique tokens.\n",
      "\n",
      "# 3. Normalize\n",
      "# remove common words like 'where'; collapse word forms like worked -> work\n",
      "terms = [\"he\", \"didnt\", \"know\", \"work\"]\n",
      "\n",
      "# 4. Index\n",
      "index = {'he': [0],\n",
      "         'didnt': [0],\n",
      "         'know' : [0],\n",
      "         'work' : [0]}"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 111
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "**e\u00b7quiv\u00b7a\u00b7lence class** (/i'kwiv\u0259l\u0259ns klas/) *n.*\n",
      "\n",
      "1. A subset whose elements are equivalent according to some relation $\\sim$ .\n",
      "\n",
      "    $S' \\subseteq S \\hspace{.2cm}$ s.t. $\\hspace{.2cm}x_i \\sim x_j \\hspace{.1cm} \\forall x_i, x_j \\in S'$\n",
      "    \n",
      "    E.g., consider the set \\{dog, cat, spider\\} and the relation \"has same number of legs\". Then there are two equivalence classes: \\{dog, cat\\} and \\{spider\\}."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "**to\u00b7ken** (/t\u014dk\u0259n/) *n*.\n",
      "\n",
      "1. A sequence of characters in a document that form a meaningful unit.\n",
      "2. The output of a *tokenizer*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "**type** (/t\u012bp/) *n.*\n",
      "\n",
      "1. An equivalence class of *tokens* under the string equality relation.\n",
      "2. By analogy to OO-programming, class:object :: type:token\n",
      "\n",
      "    *e.g., \"to be or not to be\"* $\\xrightarrow{tokenize}$ *tokens={to, be, or, not, to be}* $\\hspace{.2cm}$  *types={to, be, or, not}*\n",
      "    \n",
      "    The type 'to' is an equivalence class containing the first and fifth tokens of the document.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "**term** (/t\u0259rm/) *n.*\n",
      "\n",
      "1. An equivalence class of *types* under the relation \"have the same normalized form.\"\n",
      "2. The keys in the inverted index.\n",
      "\n",
      "    e.g., types={John, john, aren't, arent} $\\xrightarrow{normalize}$ terms={john, arent}.\n",
      "\n",
      "    The term \"john\" is an equivalence class containing types {John, john}.\n",
      "    \n",
      "    The term \"arent\" is an equivalence class containing types {arent, aren't}.\n",
      "    \n",
      "    "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Tokenization\n",
      "\n",
      "**to\u00b7ken\u00b7i\u00b7za\u00b7tion** (/\u02c8t\u014dk\u0259n iz\u0101-sh\u0259n/) *n.*\n",
      "\n",
      "1. The process of splitting a document into tokens.\n",
      "\n",
      "    *Simplest approach*: split on whitespace.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print document.split()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['he', \"didn't\", 'know', 'where', 'he', 'worked.']\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Tokenization: Compound Nouns\n",
      "\n",
      "- *San Francisco*;  *New York University* vs *York University*\n",
      "- Solved somewhat by *phrase indexing* (next class)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Tokenization: Segmentation\n",
      "\n",
      "- *Lebensversicherungsgesellschaftsangestellter*\n",
      "  - \"life insurance company employee\"\n",
      "- \u6211\u4e0d\u80fd\u8bf4\u4e2d\u56fd\u8bdd\n",
      "- *\\#androidgames*\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- Statistical classification algorithms can be used to split (Part III of course). \n",
      "- Simpler: index character subsequences (*n-grams*).\n",
      "  - E.g., *\\#androidgames* $\\rightarrow$ {*#andr, andro, ndroi, droid, roidg, ..., games*}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Tokenization: Punctuation\n",
      "\n",
      "- Remove all punctuation? "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "  - \"didn't\", \"www.google.com\"\n",
      "  - [CAR](https://www.google.com/search?q=CAR) vs [C.A.R](https://www.google.com/search?q=C.A.R.).\n",
      "  - [O'Neill vs ONeill vs O Neill](https://www.google.com/#q=oneill+-o'neill&safe=active)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Tokenization: Regular Expressions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "symbol | meaning\n",
      "------ | -------\n",
      "\\b\t| Word boundary (zero width)\n",
      "\\d\t| Any decimal digit (equivalent to [0-9])\n",
      "\\D\t| Any non-digit character (equivalent to [^0-9])\n",
      "\\s\t| Any whitespace character (equivalent to [ \\t\\n\\r\\f\\v]\n",
      "\\S\t| Any non-whitespace character (equivalent to [^ \\t\\n\\r\\f\\v])\n",
      "\\w\t| Any alphanumeric character (equivalent to [a-zA-Z0-9_])\n",
      "\\W\t| Any non-alphanumeric character (equivalent to [^a-zA-Z0-9_])\n",
      "\\t\t| The tab character\n",
      "\\n\t| The newline character\n",
      "\n",
      "(source: <http://nltk.org/book/ch03.html>)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re  # Regular expression module\n",
      "print re.split('x', 'axbxc')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['a', 'b', 'c']\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print re.split('\\+\\+', 'hi+++there')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['hi', '+there']\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print re.split('([\\W\\s]|t)', \"what's up?\")"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['wha', 't', '', \"'\", 's', ' ', 'up', '?', '']\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = \"A first-class ticket to the U.S.A. isn't expensive?\"\n",
      "print re.split(' ', text)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['A', 'first-class', 'ticket', 'to', 'the', 'U.S.A.', \"isn't\", 'expensive?']\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "How to remove punctuation?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print re.split('\\W+', text)           # \\W=not a word character; +=1 or more"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['A', 'first', 'class', 'ticket', 'to', 'the', 'U', 'S', 'A', 'isn', 't', 'expensive', '']\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print re.findall('\\w+', text)         # \\w=a word character [a-zA-Z0-9_]"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['A', 'first', 'class', 'ticket', 'to', 'the', 'U', 'S', 'A', 'isn', 't', 'expensive']\n"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# group punctuation with following letters\n",
      "print re.findall('\\w+|\\S\\w*', text)  # \\S=not a space; |=OR"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['A', 'first', '-class', 'ticket', 'to', 'the', 'U', '.S', '.A', '.', 'isn', \"'t\", 'expensive', '?']\n"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "How to keep hyphenated words and contractions together?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print re.findall(\"\\w+(?:[-']\\w+)*|[-.(]+|\\S\\w*\", text)\n",
      "# (?: specifies what to match, not what to capture"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['A', 'first-class', 'ticket', 'to', 'the', 'U', '.', 'S', '.', 'A', '.', \"isn't\", 'expensive', '?']\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print re.findall(\"(?:[A-Z]\\.)+|\\w+(?:[-']\\w+)*|[-.(]+|\\S\\w*\", text)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['A', 'first-class', 'ticket', 'to', 'the', 'U.S.A.', \"isn't\", 'expensive', '?']\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Normalization\n",
      "\n",
      "**nor\u00b7mal\u00b7iz\u00b7a\u00b7tion** (/\u02c8n\u00f4rm\u0259\u02ccliz\u0101-sh\u0259n/) *n.*\n",
      "\n",
      "1. The process of clustering *types* into *terms*.\n",
      "\n",
      "    Issues include: removing common words, special characters, casing, morphology"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Normalization: Stop words\n",
      "\n",
      "- Exclude common words\n",
      "  - *the*, *a*, *be*\n",
      "- Why?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "  - save space (length of postings list is huge!)\n",
      "  - no semantic content (?!)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "*\"[to be or not to be](https://www.google.com/search?q=to+be+or+not+to+be&oq=to+be+or+not+to+be)\"* is all stop words!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Accents/Diacritics\n",
      "\n",
      "- naive vs. na\u00efve\n",
      "- pena (sorrow) vs pe\u00f1a (cliff)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- What will users enter?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Case\n",
      "\n",
      "- Typically, just convert everything to lowercase.\n",
      "- E.g., search Google for [CAT -cat](https://www.google.com/search?q=CAT+-cat)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Stemming / Lemmatizing\n",
      "\n",
      "**mor\u00b7phol\u00b7o\u00b7gy** (/m\u00f4r\u02c8f\u00e4l\u0259j\u0113/) *n.*\n",
      "\n",
      "1. (*Linguistics*) The study of the rules governing how words may take different forms in a language.\n",
      "\n",
      "*E.g.* \n",
      "\n",
      "- Pluralization: *dog* $\\xrightarrow{pluralize}$ *dogs* ; *goose* $\\xrightarrow{pluralize}$ *geese*\n",
      "\n",
      "\n",
      "- Tense: *play* $\\xrightarrow{past.tense}$ *played* ; *go* $\\xrightarrow{past.tense}$ *went*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "**stem** (/stem/) *v.*\n",
      "\n",
      "1. To normalize based on crude morphology heuristics.\n",
      "\n",
      "    *E.g. remove all \"-s\" and \"-ed\" suffixes*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "**lem\u00b7ma\u00b7tize** (\u02c8lem\u0259\u02cct\u012bz/) *v.*\n",
      "\n",
      "1. To create equivalence classes of word types using the morphological rules of a language.\n",
      "\n",
      "    *Often relies on **part-of-speech** tagging to select rules*.\n",
      "\n",
      "    *E.g. if * bed * is a noun, then do not remove * -ed *suffix.*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Simple stemmer\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def stem(word):\n",
      "    for suffix in ['ies', 's', 'ed', 'ing']: # order matters!\n",
      "        if word.endswith(suffix):\n",
      "            return word[:-len(suffix)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "**What can go wrong?**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Stemming Errors\n",
      "\n",
      "- **over-stemming**: merge types that should not be merged.\n",
      "- **under-stemming**: fail to merge types that should be merged."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "types = ['tied', 'ties', 'tis', 'bed', 'cities']\n",
      "print '\\n'.join([stem(w) for w in types])"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'stem' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-46-7154f802d81c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'tied'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ties'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'stem' is not defined"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "**How does this affect search?**"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Porter Stemmer\n",
      "\n",
      "- Very commonly used stemmer with a complex set of heuristics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.stem import PorterStemmer # See nltk.org (`pip install nltk`)\n",
      "porter = PorterStemmer()\n",
      "print types\n",
      "print '\\n'.join([porter.stem(x) for x in types])"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'types' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-45-15fdbdb8f5d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m \u001b[0;31m# See nltk.org (`pip install nltk`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mporter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'types' is not defined"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "types = ['bed', 'kiss',\n",
      "         'tied', 'tis',\n",
      "         'universal', 'university',\n",
      "         'experiment', 'experience',\n",
      "         'past', 'paste',\n",
      "         'alumnus', 'alumni',\n",
      "         'adhere', 'adhesion',\n",
      "         'create', 'creation']\n",
      "porter_results = [porter.stem(x) for x in types]\n",
      "print '\\n'.join(porter_results)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "bed\n",
        "kiss\n",
        "tie\n",
        "ti\n",
        "univers\n",
        "univers\n",
        "experi\n",
        "experi\n",
        "past\n",
        "past\n",
        "alumnu\n",
        "alumni\n",
        "adher\n",
        "adhes\n",
        "creat\n",
        "creation\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# WordNet Lemmatizer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.stem.wordnet import WordNetLemmatizer\n",
      "# See description: https://wordnet.princeton.edu/wordnet/man/morphy.7WN.html\n",
      "lemm = WordNetLemmatizer()\n",
      "lemm_results = [lemm.lemmatize(x) for x in types]\n",
      "print 'type, porter, lemmatizer\\n'\n",
      "print '\\n'.join([str(t) for t in zip(types, porter_results, lemm_results)])"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "type, porter, lemmatizer\n",
        "\n",
        "('bed', 'bed', 'bed')\n",
        "('kiss', 'kiss', 'kiss')\n",
        "('tied', 'tie', 'tied')\n",
        "('tis', 'ti', 'ti')\n",
        "('universal', 'univers', 'universal')\n",
        "('university', 'univers', 'university')\n",
        "('experiment', 'experi', 'experiment')\n",
        "('experience', 'experi', 'experience')\n",
        "('past', 'past', 'past')\n",
        "('paste', 'past', 'paste')\n",
        "('alumnus', 'alumnu', 'alumnus')\n",
        "('alumni', 'alumni', 'alumnus')\n",
        "('adhere', 'adher', 'adhere')\n",
        "('adhesion', 'adhes', 'adhesion')\n",
        "('create', 'creat', 'create')\n",
        "('creation', 'creation', 'creation')\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# A principled approach?\n",
      "\n",
      "Given the many number of ways to preprocess text, how do we know which one is best?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Approaches:\n",
      "\n",
      "- Assume types that appear in similar contexts can be merged.\n",
      "  - e.g., *universally* and *universal* appear in similar documents, but not *university*."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "- Learn from user behavior\n",
      "  - e.g., users click on very different search results if they search for *universal* vs *university*.\n",
      "  \n",
      "We'll explore both later in the course."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}