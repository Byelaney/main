{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CS429: Information Retrieval\n",
    "\n",
    "<br>\n",
    "\n",
    "## Lecture 15: Classification and Machine Learning\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dr. Aron Culotta\n",
    "### Illinois Institute of Technology\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "- [Dietterich: \"Machine Learning\"](http://web.engr.oregonstate.edu/~tgd/publications/nature-ecs-machine-learning.pdf)\n",
    "- [Domingos: \"A few useful things to know about machine learning\"](http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "\"Study of methods for programming computers to learn.\" \n",
    "\n",
    "-- Dietterich\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "Study of systems that \"automatically learn programs from data\" \n",
    "\n",
    "-- Domingos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "A problem-solving technique that solves future problem instances based on\n",
    "patterns found in past problem instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![spam](images/spam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/search.png' width='50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/netflix.png', width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/bw.png' width='50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/chopper.png' width='70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/car.jpg' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![money](images/money.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/doc.png' width='40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/siri.png' width='40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/watson.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notation\n",
    "\n",
    "- $\\vec{x} \\in \\mathcal{X}$ &nbsp;&nbsp;&nbsp;&nbsp; *instance*, *example*, *input*\n",
    "  - e.g., an email\n",
    "- $y \\in \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *target*, *class*, *label*, *output*\n",
    "  - e.g., $y=1$: spam ; $y=0$: not spam\n",
    "- $f: \\mathcal{X} \\mapsto \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *hypothesis*, *learner*, *model*, *classifier*\n",
    "  - e.g., if $x$ contain the word *free*, $y$ is $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem types\n",
    "\n",
    "- **Classification**\n",
    "  - $\\vec{x}$: image of a person ;  $y$: gender\n",
    "- **Regression**\n",
    "  - $\\vec{x}$: image of a person ; $y$: age\n",
    "- **Clustering**\n",
    "  - $\\vec{x}$: images of people ; $y$: cluster id of people that look similar\n",
    "- **Structured classification**\n",
    "  - $\\vec{x}$: image of a person ; $\\vec{y}$: location of their eyes and ears\n",
    "  - $X$: sequence of images of people ; $Y$: subsequences containing people running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow\n",
    "\n",
    "1. **Collect** raw data: emails\n",
    "2. Manually **categorize** them:  spam or not\n",
    "3. **Vectorize**: email -> word counts [**features**]\n",
    "4. **Train** / **Fit**: create $f(x)$\n",
    "5. **Collect** new raw data\n",
    "6. **Predict**: compute $f(x)$ for new $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Spam Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Steps 1 & 2: Collect and categorize**\n",
    "\n",
    "**Spam:**\n",
    "\n",
    "> Free credit report!\n",
    "\n",
    "\n",
    "> Free money!\n",
    "\n",
    "\n",
    "**Not spam:**\n",
    "\n",
    "> Are you free tonight?\n",
    "\n",
    "> How are you?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Step 3: Vectorize**\n",
    "\n",
    "> 'Free money!'\n",
    "\n",
    "becomes\n",
    "\n",
    "```\n",
    "free: 1\n",
    "money: 1\n",
    "!: 1\n",
    "?: 0\n",
    "credit: 0\n",
    "...\n",
    "```\n",
    "\n",
    "**Representation**: \"Feature engineering is the key\" -- Domingos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Step 4: Train/Fit**\n",
    "\n",
    "Which model to use?\n",
    "\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- K-Nearest Neighbors\n",
    "- Support Vector Machines\n",
    "- ... many many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Steps 5-6: Predict on new data**\n",
    "\n",
    "> Free vacation!\n",
    "\n",
    "**Spam**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# X: each row is a feature vector for one document.\n",
    "X = [(0, 0),\n",
    "     (1, 0),\n",
    "     (0,3),\n",
    "     (1,3)]\n",
    "# y: element i is a label for ith document\n",
    "y = [0, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1087e5550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data. \n",
    "# Red means class 0, blue means class 1.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_data(X, y):\n",
    "    \"\"\" Assumes 2-d data. \"\"\"\n",
    "    plt.figure()\n",
    "    for xi, yi in zip(X, y):\n",
    "        color = 'r' if yi == 0 else 'b'\n",
    "        plt.plot(xi[0], xi[1], color + 'o', ms=20)\n",
    "    plt.xlabel('feature 0')\n",
    "    plt.ylabel('feature 1')\n",
    "    plt.xlim((-1,2))\n",
    "    plt.ylim((-1, 4))\n",
    "    plt.annotate('class 0', xy=(1.2, 0), color='r', size=15)\n",
    "    plt.annotate('class 1', xy=(1.2, 3), color='b', size=15)\n",
    "    plt.show()\n",
    "    \n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Simplest machine learning algorithm:\n",
    "\n",
    "class SimplestMachine:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.f = dict()\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for xi, yi in zip(X, y):\n",
    "          self.f[xi] = yi\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.f[x]\n",
    "\n",
    "# What does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred\ttruth\n",
      " 0\t0\n",
      "0\t0\n",
      "1\t1\n",
      "1\t1\n"
     ]
    }
   ],
   "source": [
    "simplest_machine = SimplestMachine()\n",
    "simplest_machine.train(X, y)\n",
    "predictions = [simplest_machine.predict(xi) for xi in X]\n",
    "print('pred\\ttruth\\n', '\\n'.join('%d\\t%d' % (p, yi) for p, yi in zip(predictions, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9cba31281ef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# What does it do for unseen example?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimplest_machine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-55d614d1ae88>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# What does this do?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 4)"
     ]
    }
   ],
   "source": [
    "# What does it do for unseen example?\n",
    "simplest_machine.predict((0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Second simplest machine learning algorithm:\n",
    "import numpy as np\n",
    "\n",
    "class SimpleMachine:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.f = dict()\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for xi, yi in zip(X, y):\n",
    "          self.f[xi] = yi\n",
    "\n",
    "    def predict(self, x):\n",
    "        x_closest = self.find_most_similar(x)\n",
    "        return self.f[x_closest]\n",
    "    \n",
    "    def find_most_similar(self, x):\n",
    "        best_idx = np.argmin([self.distance(x, xi) for xi in self.f.keys()])\n",
    "        return list(self.f.keys())[best_idx]\n",
    "\n",
    "    def distance(self, x, xi):\n",
    "        return np.sqrt(np.sum((np.array(x)-np.array(xi))**2))\n",
    "        \n",
    "# What does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred\ttruth\n",
      " 0\t0\n",
      "0\t0\n",
      "1\t1\n",
      "1\t1\n"
     ]
    }
   ],
   "source": [
    "simple_machine = SimpleMachine()\n",
    "simple_machine.train(X, y)\n",
    "predictions = [simple_machine.predict(xi) for xi in X]\n",
    "print('pred\\ttruth\\n', '\\n'.join('%d\\t%d' % (p, yi) for p, yi in zip(predictions, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does it do for unseen example?\n",
    "simple_machine.predict((0, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/knn.png' width='80%'/>\n",
    "\n",
    "<http://www.scholarpedia.org/article/K-nearest_neighbor>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Generalization\n",
    "\n",
    "How accurate will I be on a new, unobserved example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "   - Why not ${\\mathcal D_1}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "4. Tweak algorithm / representation\n",
    "5. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "4. Tweak algorithm / representation\n",
    "5. Repeat\n",
    "\n",
    "How many times can I do this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring Generalization\n",
    "\n",
    "- Cross-validation\n",
    "  - train on 90%, test on 10%, repeat 10 x's\n",
    "        - each example appears only once in test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experimental Design\n",
    "\n",
    "1. Collect data\n",
    "2. Build model\n",
    "3. Compute cross-validation accuracy\n",
    "4. Tune model\n",
    "5. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Experimental Design\n",
    "\n",
    "1. Collect data\n",
    "2. Build model\n",
    "3. Compute cross-validation accuracy\n",
    "4. Tune model\n",
    "5. Repeat\n",
    "6. **Report accuracy on new data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- What is overfitting? How do you know it is happening? How do you fix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/biasvariance.png' width='70%'/>\n",
    "\n",
    "<http://scott.fortmann-roe.com/docs/BiasVariance.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning for Sentiment Analysis\n",
    "\n",
    "1. Collect data: E.g., <http://help.sentiment140.com/for-students>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Download Twitter data labeled by sentiment.\n",
    "\n",
    "import zipfile\n",
    "from urllib.request import urlretrieve\n",
    "# The file is 78M, so this will take a while.\n",
    "url = urlretrieve('http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip', 'data.zip')\n",
    "zfile = zipfile.ZipFile('data.zip')\n",
    "zfile.extractall()\n",
    "\n",
    "#zipfile = ZipFile(StringIO(url.read()))\n",
    "# We'll focus on the smaller file that was manually labeled.\n",
    "# The larger file has 1.6M tweets \"pseudo-labeled\" using emoticons\n",
    "tweet_file = open('testdata.manual.2009.06.14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"4\",\"3\",\"Mon May 11 03:17:40 UTC 2009\",\"kindle2\",\"tpryan\",\"@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.\"\r\n",
      "\"4\",\"4\",\"Mon May 11 03:18:03 UTC 2009\",\"kindle2\",\"vcu451\",\"Reading my kindle2...  Love it... Lee childs is good read.\"\r\n",
      "\"4\",\"5\",\"Mon May 11 03:18:54 UTC 2009\",\"kindle2\",\"chadfu\",\"Ok, first assesment of the #kindle2 ...it fucking rocks!!!\"\r\n",
      "\"4\",\"6\",\"Mon May 11 03:19:04 UTC 2009\",\"kindle2\",\"SIX15\",\"@kenburbary You'll love your Kindle2. I've had mine for a few months and never looked back. The new big one is huge! No need for remorse! :)\"\r\n",
      "\"4\",\"7\",\"Mon May 11 03:21:41 UTC 2009\",\"kindle2\",\"yamarama\",\"@mikefish  Fair enough. But i have the Kindle2 and I think it's perfect  :)\"\r\n",
      "\"4\",\"8\",\"Mon May 11 03:22:00 UTC 2009\",\"kindle2\",\"GeorgeVHulme\",\"@richardebaker no. it is too big. I'm quite happy with the Kindle2.\"\r\n",
      "\"0\",\"9\",\"Mon May 11 03:22:30 UTC 2009\",\"aig\",\"Seth937\",\"Fuck this economy. I hate aig and their non loan given asses.\"\r\n",
      "\"4\",\"10\",\"Mon May 11 03:26:10 UTC 2009\",\"jquery\",\"dcostalis\",\"Jquery is my new best friend.\"\r\n",
      "\"4\",\"11\",\"Mon May 11 03:27:15 UTC 2009\",\"twitter\",\"PJ_King\",\"Loves twitter\"\r\n",
      "\"4\",\"12\",\"Mon May 11 03:29:20 UTC 2009\",\"obama\",\"mandanicole\",\"how can you not love Obama? he makes jokes about himself.\"\r\n"
     ]
    }
   ],
   "source": [
    "!head testdata.manual.2009.06.14.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 498 tweets\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "file_reader = csv.reader(tweet_file, delimiter=',', quotechar='\"')\n",
    "tweets = []\n",
    "for row in file_reader:\n",
    "    tweets.append({'label': int(row[0]),\n",
    "                   'text': row[5]})\n",
    "print 'read %d tweets' % len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label counts= Counter({4: 182, 0: 177, 2: 139})\n"
     ]
    }
   ],
   "source": [
    "# Create label vector (y) and print its stats.\n",
    "from collections import Counter\n",
    "y = np.array([t['label'] for t in tweets])\n",
    "print 'label counts=', Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorized 498 tweets. found 2264 terms.\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors (X)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(t['text'] for t in tweets)\n",
    "print 'vectorized %d tweets. found %d terms.' % (X.shape[0], X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'msgs', 1325), (u'whoopi', 2176), (u'sleep', 1804), (u'6pm', 67), (u'hate', 920), (u'whose', 2177), (u'boortz', 317), (u'davehitt', 557), (u'bike', 276), (u'under', 2072)]\n"
     ]
    }
   ],
   "source": [
    "# Print part of the vocabulary.\n",
    "print vectorizer.vocabulary_.items()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_indices= [1961 1998  988 ..., 1363 1364    0]\n",
      "top_terms:\n",
      "the 1961\n",
      "to 1998\n",
      "http 988\n",
      "is 1060\n",
      "and 152\n",
      "at 209\n",
      "it 1062\n",
      "for 790\n",
      "my 1337\n",
      "of 1416\n"
     ]
    }
   ],
   "source": [
    "# What are the most frequent terms?\n",
    "# Sum columns:\n",
    "col_sums = X.sum(axis=0).tolist()[0]\n",
    "# Sort sums in descending order, and return the indices.\n",
    "top_indices = np.argsort(col_sums)[::-1]\n",
    "print 'top_indices=', top_indices\n",
    "vocab = np.array(vectorizer.get_feature_names())\n",
    "top_terms = vocab[top_indices]\n",
    "print('top_terms:\\n', '\\n'.join('%s %d' % (term, count) for term, count in zip(top_terms, top_indices)[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.) Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data=0.996\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "def accuracy(truth, predicted):\n",
    "    return (1. * len([1 for tr, pr in zip(truth, predicted) if tr == pr]) / len(truth))\n",
    "\n",
    "predicted = model.predict(X)\n",
    "print 'accuracy on training data=%.3f' % accuracy(y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top weighted terms for positive class:\n",
      "awesome 1.52\n",
      "love 1.51\n",
      "g2 1.23\n",
      "good 1.17\n",
      "kindle2 1.03\n",
      "lebron 0.95\n",
      "great 0.89\n",
      "mcdonalds 0.81\n",
      "tonight 0.80\n",
      "mashable 0.80\n"
     ]
    }
   ],
   "source": [
    "# What are the top weighted features?\n",
    "\n",
    "# Get the learned coefficients for the Positive class.\n",
    "coef = model.coef_[2]\n",
    "# Sort them in descending order.\n",
    "top_coef_ind = np.argsort(coef)[::-1]\n",
    "# Get the names of those features.\n",
    "top_coef_terms = vocab[top_coef_ind]\n",
    "# Get the weights of those features\n",
    "top_coef = coef[top_coef_ind]\n",
    "# Print the top 10.\n",
    "print 'top weighted terms for positive class:\\n', \\\n",
    "    '\\n'.join('%s %.2f' % (term, weight) for term, weight in zip(top_coef_terms, top_coef)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top weighted terms for negative class:\n",
      "warner 1.56\n",
      "hate 1.29\n",
      "aig 1.28\n",
      "gm 1.08\n",
      "korea 1.06\n",
      "north 1.06\n",
      "not 1.05\n",
      "cheney 0.94\n",
      "that 0.89\n",
      "fail 0.89\n"
     ]
    }
   ],
   "source": [
    "# Get the learned coefficients for the Negative class.\n",
    "coef = model.coef_[0]\n",
    "# Sort them in descending order.\n",
    "top_coef_ind = np.argsort(coef)[::-1]\n",
    "# Get the names of those features.\n",
    "top_coef_terms = vocab[top_coef_ind]\n",
    "# Get the weights of those features\n",
    "top_coef = coef[top_coef_ind]\n",
    "# Print the top 10.\n",
    "print 'top weighted terms for negative class:\\n', \\\n",
    "    '\\n'.join('%s %.2f' % (term, weight) for term, weight in zip(top_coef_terms, top_coef)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-fold cross validation accuracy=0.67 (std=0.04)\n"
     ]
    }
   ],
   "source": [
    "# 5 Cross-validation accuracy\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "cv = KFold(len(y), 5)\n",
    "accuracies = []\n",
    "for train_ind, test_ind in cv:\n",
    "    model.fit(X[train_ind], y[train_ind])\n",
    "    predictions = model.predict(X[test_ind])\n",
    "    accuracies.append(accuracy(y[test_ind], predictions))\n",
    "    \n",
    "print 'Average 5-fold cross validation accuracy=%.2f (std=%.2f)' % (np.mean(accuracies), np.std(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Midterm Review\n",
    "\n",
    "**Problem types:**\n",
    "\n",
    "- Algorithm output (50%)\n",
    "  - e.g., score documents according to X\n",
    "  - levenshtein distance\n",
    "  - skip-lists\n",
    "  - tokenize/stem\n",
    "  - evaluation\n",
    "\n",
    "\n",
    "- Algorithm invention (30%)\n",
    "  - I give you code, and I ask you to change it\n",
    "  - E.g., modify tf-idf to prefer newer documents \n",
    "\n",
    "\n",
    "- Efficiency / Analysis of algorithm (10%)\n",
    "  - I give you algorithm, you tell me how to make it more more efficient/more accurate\n",
    "  - E.g., $n^2$ -> $n$\n",
    "\n",
    "\n",
    "- True/False (10%)\n",
    "\n",
    "\n",
    "\n",
    "**Topics:**\n",
    "\n",
    "- Indexing\n",
    "  - type/token/term\n",
    "  - tokenization\n",
    "  - lemmatization\n",
    "  - stemming\n",
    "  - stopping\n",
    "\n",
    "\n",
    "- efficient query processing\n",
    "  - and\n",
    "  - or\n",
    "  - not\n",
    "  - phrases\n",
    "  - skip lists\n",
    "\n",
    "\n",
    "- spelling correction\n",
    "  - levenshtein\n",
    "\n",
    "\n",
    "\n",
    "- Zipf\n",
    "\n",
    "- Heap\n",
    "\n",
    "\n",
    "- Ranking\n",
    "  - tf\n",
    "  - idf\n",
    "  - approximate k-best\n",
    "    - champion list\n",
    "    - cluster pruning\n",
    "  - field search\n",
    "  - Binary Independence Model\n",
    "  - BM25\n",
    "  - cosine similarity\n",
    "  - language model\n",
    "    - smoothing / interpolation\n",
    "  - cosine similarity vs euclidean distance\n",
    "  - Relevance feedback\n",
    "\n",
    "- Evaluation\n",
    "  - precision\n",
    "  - recall\n",
    "  - f1\n",
    "  - precision/recall curve\n",
    "  - Mean Average Precision\n",
    "\n",
    "- Formulae you should know:\n",
    " - precision, recall\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
