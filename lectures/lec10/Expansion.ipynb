{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CS 429: Information Retrieval\n",
    "\n",
    "<br>\n",
    "\n",
    "## Lecture 10: Query Expansion\n",
    "\n",
    "<br>\n",
    "\n",
    "### Dr. Aron Culotta\n",
    "### Illinois Institute of Technology \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Last time:\n",
    "\n",
    "- Evaluation\n",
    "  - accuracy, precision, recall, MAP\n",
    "  \n",
    "This time:\n",
    "\n",
    "- How can we incoporate user feedback to improve search?\n",
    "- How can we alter the user's query to improve search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Relevance Feedback\n",
    "\n",
    "- An *interactive* IR system in which \n",
    "\n",
    "\n",
    "1. The user enters a query.\n",
    "2. The system returns results.\n",
    "3. The user indicates which results are relevant.\n",
    "4. GoTo 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How should we incorporate user feedback?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Create a new query that is similar to relevant documents but dissimilar to irrelevant documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Rocchio\n",
    "\n",
    "$ \\DeclareMathOperator*{\\argmax}{arg\\,max}$\n",
    "$\\vec{q}^* \\leftarrow \\argmax_{\\vec{q}} sim(\\vec{q}, C_r) - sim(\\vec{q}, C_{nr})$\n",
    "\n",
    "- where $q$ is a query\n",
    "- $C_r$ is a set of relevant documents\n",
    "- $C_{nr}$ is a set of irrelevant documents\n",
    "- $sim$ is cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Document Centroid\n",
    "\n",
    "Recall that we represent each document as a vector of tf-idf values.\n",
    "\n",
    "Given a collection of documents $D = \\{\\vec{d_1} \\ldots \\vec{d_N}\\}$, the centroid vector is:\n",
    "\n",
    "$$ \\frac{1}{N} \\sum_{\\vec{d_j} \\in D}\\vec{d}_j $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A word about numpy arrays...\n",
    "import numpy as np\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "print('list addition:', a + b)\n",
    "print('numpy array addition:', np.array(a) + np.array(b))\n",
    "print('numpy array division:', np.array(a) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list division? Nope.\n",
    "a / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "points = [[1, 4],\n",
    "          [.5, .5],\n",
    "          [4, 6]]\n",
    "\n",
    "# Compute centroid.\n",
    "centroid = np.sum(points, axis=0) / len(points)\n",
    "plt.figure()\n",
    "plt.scatter([p[0] for p in points],\n",
    "            [p[1] for p in points])\n",
    "plt.scatter([centroid[0]],\n",
    "            [centroid[1]], marker='x', s=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Want a query that is closest to relevant documents, but far from irrelevant documents.\n",
    "\n",
    "$$\\vec{q}^* = \\frac{1}{|C_r|} \\sum_{\\vec{d_j} \\in C_r}\\vec{d}_j - \\frac{1}{|C_{nr}|} \\sum_{\\vec{d}_j \\in C_{nr}} \\vec{d}_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rocchio](files/rocchio.png)\n",
    "\n",
    "Source: [MRS](http://nlp.stanford.edu/IR-book/pdf/09expand.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But, we don't know the set of all relevant and irrelevant documents.\n",
    "\n",
    "\n",
    "$$\\vec{q}_m = \\alpha \\vec{q}_0 + \\beta\\frac{1}{D_r} \\sum_{\\vec{d}_j \\in D_r} \\vec{d}_j - \\gamma\\frac{1}{|D_{nr}|} \\sum_{\\vec{d_j} \\in D_{nr}} \\vec{d}_j$$\n",
    "\n",
    "- $\\vec{q}_0$ is original query vector\n",
    "- $\\alpha$, $\\beta$, $\\gamma$ are tunable parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot effect of relevance feedback as we change parameters.\n",
    "import numpy as np\n",
    "from numpy import array as npa\n",
    "import random as rnd\n",
    "\n",
    "def centroid(docs):\n",
    "    return np.sum(docs, axis=0) / len(docs)\n",
    "\n",
    "def rocchio(query, relevant, irrelevant, alpha, beta, gamma):\n",
    "    return alpha * query + beta * centroid(relevant) - gamma * centroid(irrelevant) \n",
    "\n",
    "# Create some documents\n",
    "relevant = npa([[1, 5], [1.1, 5.1], [0.9, 4.9], [1.0, 4.8]])\n",
    "irrelevant = npa([[rnd.random()*6, rnd.random()*6] for i in range(30)])\n",
    "\n",
    "# Create a query\n",
    "query = npa([.1, .1])\n",
    "\n",
    "# Compute two different Rocchio updates (gamma=0.5, gamma=0)\n",
    "new_query_g5 = rocchio(query, relevant, irrelevant, 1., .75, .5)\n",
    "new_query_g0 = rocchio(query, relevant, irrelevant, 1., .75, 0.)\n",
    "new_query_g0_a0 = rocchio(query, relevant, irrelevant, 0., .75, 0.)\n",
    "\n",
    "# Plot them.\n",
    "plt.figure()\n",
    "pos = plt.scatter([p[0] for p in relevant], [p[1] for p in relevant],\n",
    "                  color='g', marker='o', label='relevant')\n",
    "neg = plt.scatter([p[0] for p in irrelevant], [p[1] for p in irrelevant],\n",
    "              marker='+', color='red', label='irrelevant')\n",
    "\n",
    "q = plt.scatter(query[0], query[1], marker='v',\n",
    "                color='b', s=100, label='query')\n",
    "newq_b5 = plt.scatter([new_query_g5[0]], [new_query_g5[1]],\n",
    "                      marker='*', s=100, color='black', label='gamma=.5')  # s=100, c=.9)\n",
    "#newq_b0 = plt.scatter([new_query_g0[0]], [new_query_g0[1]],\n",
    "#                      marker='d', s=100, color='black', label='gamma=0')  # s=100, c=.8)\n",
    "newq_b0 = plt.scatter([new_query_g0_a0[0]], [new_query_g0_a0[1]],\n",
    "                      marker='^', s=100, color='black', label='gamma=0')  # s=100, c=.8)\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $\\gamma=0$ Often used, since we're more confident in relevant annotations than irrelevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One might decrease $\\alpha$ as the number of relevant documents increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Does relevance feedback help precision or recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Mostly recall: \"adding\" similar terms to query vector from relevant documents.\n",
    "\n",
    "- When would it not help?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Spelling correction?\n",
    "- Different language?\n",
    "- Synonyms?\n",
    "\n",
    "\n",
    "- Assumption 1: query is \"close\" to relevant documents\n",
    "  - feedback makes the query closer\n",
    "  \n",
    "- Assumption 2: relevant documents form one cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# What happens if there are two clusters of relevant examples?\n",
    "\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "points = [[1, 5], [1.1, 5.1], [0.9, 4.9], [1.0, 4.8],\n",
    "          [5, 1.2], [4.9, 1.1], [5.1, 1.0], [4.8,1.2]]\n",
    "plt.figure()\n",
    "centroid = np.sum(points, axis=0) / len(points)\n",
    "pos = plt.scatter([p[0] for p in points], [p[1] for p in points], \n",
    "                 color='green', label='relevant')\n",
    "neg = plt.scatter([rnd.random()*6 for i in range(30)],\n",
    "                  [rnd.random() * 6 for i in range(30)],\n",
    "                  marker='+', color='red', label='irrelevant')\n",
    "centroid = plt.scatter([centroid[0]], [centroid[1]],\n",
    "                   marker='x', s=100, color='blue', label='centroid')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"If you have your one foot in a bucket of boiling hot water and another foot in a bucket of ice cold water, on average you ought to feel pretty comfortable.\"* --Unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Does relevance feedback affect search time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Much longer queries\n",
    "- How to approximate?\n",
    "  - Use top $k$ most informative terms from relevant set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variants of relevance feedback\n",
    "\n",
    "- Pseudo-relevance: Assume top $k$ documents are relevant.\n",
    "- Indirect relevance: Mine click logs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pseudo-relevance feedback\n",
    "\n",
    "1. Rank documents\n",
    "2. Let $V$ be the top $k$ documents. We pretend these are all relevant.\n",
    "3. Update $q$ according to Rocchio\n",
    "\n",
    "We can iterate steps $2-3$ until ranking stops changing.\n",
    "\n",
    "When would this work? When would this not work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Explicit query expansion\n",
    "\n",
    "- Thesaurus\n",
    "- Word co-occurrences\n",
    "- Mine reformulations from query log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# WordNet\n",
    "\n",
    "<http://wordnetweb.princeton.edu/perl/webwn>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "# Thesaurus discovery\n",
    "\n",
    "**Idea:** Look for words that occur in same context.\n",
    "\n",
    "- \"He put the mug on the \\_\\_\\_\\_\\_\"\n",
    "\n",
    "- \"He put his feet on the \\_\\_\\_\\_\"\n",
    "\n",
    "Query: \"cheap tables\" \n",
    "  - expand to include \"affordable ottomans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_context(tokens, position, window):\n",
    "    \"\"\" Get tokens to the left and right of this position.\n",
    "    Params:\n",
    "      tokens.....list of strings in this sentence\n",
    "      position...integer. index into tokens\n",
    "      window.....integer. number of tokens to the left and right to consider.\n",
    "    \"\"\"\n",
    "    start = max(position - window, 0)\n",
    "    end = min(position + window + 1, len(tokens))\n",
    "    left = ['L=%s' % x for x in tokens[start : position]]\n",
    "    right = ['R=%s' % x for x in tokens[position + 1 : end]]\n",
    "    return left + right\n",
    "    \n",
    "get_context(['a', 'b', 'c', 'd', 'e'], position=2, window=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import re\n",
    "docs = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes')).data\n",
    "print('read', len(docs), 'docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Count words that occur within a window of -n to +n of each word.\n",
    "def term2contexts(docs, n):\n",
    "    contexts = defaultdict(lambda: Counter())\n",
    "    for d in docs:\n",
    "        toks = re.findall('\\w+', d.lower())\n",
    "        for i in range(len(toks)):\n",
    "            contexts[toks[i]].update(get_context(toks, i, n))\n",
    "    return contexts\n",
    "\n",
    "contexts = term2contexts(docs, n=2)\n",
    "# Print top contexts for email\n",
    "contexts['email'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NB: Efficiently incrementing a Counter using the .update method.\n",
    "from collections import Counter\n",
    "c = Counter()\n",
    "c.update([1,2,1,1,3])\n",
    "print(c)\n",
    "c.update([3,3,3])\n",
    "print(c)\n",
    "print(c.most_common(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('made context vectors for %d terms' % len(contexts))\n",
    "# Each word now has a \"context vector\" indicating\n",
    "# the terms that often occur before/after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contexts['believe'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Downweighting common terms with IDF.\n",
    "# Compute inverse document frequency values for each term.\n",
    "# Here: document frequency means how many different contexts this feature appears in.\n",
    "import math\n",
    "def compute_idfs(contexts):\n",
    "    idfs = Counter()\n",
    "    for term, context in contexts.items():\n",
    "        idfs.update(context.keys())\n",
    "    for d in idfs:\n",
    "        idfs[d] = math.log10(len(contexts) / idfs[d])\n",
    "    return idfs\n",
    "\n",
    "idfs = compute_idfs(contexts)\n",
    "print('idf of L=the:', idfs['L=the'], ' of L=mouse:', idfs['L=mouse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multiply each context value by its idf\n",
    "idf_contexts = {}\n",
    "for term, counts in contexts.items():\n",
    "    newcounts = defaultdict(lambda: 0)\n",
    "    for term2, value in counts.items():\n",
    "        if value > 1:  # remove context terms that don't occur at least twice, to reduce noise.\n",
    "            newcounts[term2] = 1 + math.log10(value) * idfs[term2]\n",
    "    idf_contexts[term] = newcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(idf_contexts['email'].items(), key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(idf_contexts['believe'].items(), key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter terms that don't appear very often.\n",
    "idf_contexts = dict([(term, cont) for term, cont in idf_contexts.items()\n",
    "                     if len(cont) > 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(idf_contexts), 'remain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def norm(context):\n",
    "    return math.sqrt(sum(x**2 for x in context.values()))\n",
    "    \n",
    "def cosine(term1, term2, contexts):\n",
    "    # Compute cosine similarity between term1\n",
    "    # and term2 context vectors.\n",
    "    # NB: slow!\n",
    "    context1 = contexts[term1]\n",
    "    context2 = contexts[term2]\n",
    "    dotprod = sum(context1[term] * context2[term] for term in context1)\n",
    "    return dotprod / (norm(context1) * norm(context2))\n",
    "\n",
    "def find_closest_terms(term, contexts):\n",
    "    cosines = [(term2, cosine(term, term2, contexts)) for term2 in contexts]\n",
    "    return sorted(cosines, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "find_closest_terms('believe', idf_contexts)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_closest_terms('email', idf_contexts)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_closest_terms('mouse', idf_contexts)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_closest_terms('difficult', idf_contexts)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_closest_terms('love', idf_contexts)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_closest_terms('heaven', idf_contexts)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Google's $n$-gram data: \n",
    "\n",
    "<http://googleresearch.blogspot.com/2006/08/all-our-n-gram-are-belong-to-you.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How do we decide when to expand the query?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Few results returned.\n",
    "- Query log data\n",
    "  - Searches where few results are clicked."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
